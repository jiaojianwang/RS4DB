{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dis = pd.read_csv('D:\\python_code\\work2\\data_used\\dis_before_baseline_merged.csv') #发生在touchscreen0.0之前的疾病\n",
    "touch_data = pd.read_csv('D:\\python_code\\work2\\single data\\data_processed\\Touchscreen_85.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482080, 86)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "touch_data = touch_data.mask(touch_data < 0)\n",
    "\n",
    "missing_counts = touch_data.isnull().sum(axis=1)\n",
    "threshold = 0.2 * touch_data.shape[1]\n",
    "\n",
    "touch = touch_data[missing_counts < threshold]\n",
    "touch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_health = dis.iloc[:, 1:12]\n",
    "dis['mental'] = mental_health.sum(axis=1)\n",
    "physical_health = dis.iloc[:, 12:-1]\n",
    "dis['physical'] = physical_health.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis['Multi'] = dis[['mental','physical']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482057, 89)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = dis[['eid', 'mental', 'physical', 'Multi']].copy()\n",
    "data = pd.merge(touch, sum, on='eid') #touch\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gmv_data = pd.read_csv('D:/python_code/work2/brain_data_structure/GMV_2.0_dropna.csv')\n",
    "fa_data = pd.read_csv('D:/python_code/work2/brain_data_structure/FA_2.0_dropna.csv')\n",
    "gmv_eid = gmv_data['eid']\n",
    "fa_eid = fa_data['eid']\n",
    "\n",
    "protein_data = pd.read_csv('D:/python_code/work2/protein/protein_ins0.csv')\n",
    "protein_eid = protein_data['eid']\n",
    "\n",
    "combined_eid = pd.concat([gmv_eid, fa_eid, protein_eid]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trian and test data: (391193, 89)\n",
      "validation data: (90864, 89)\n"
     ]
    }
   ],
   "source": [
    "trian_data = data[~data['eid'].isin(combined_eid)].copy()\n",
    "validation_data = data[data['eid'].isin(combined_eid)].copy()\n",
    "\n",
    "print('trian and test data:', trian_data.shape)\n",
    "print('validation data:', validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test = train_test_split(trian_data, test_size=0.3, random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "features = x_train.iloc[:, 1:-3].values\n",
    "variant = x_train[['eid','mental','physical','Multi']].copy()\n",
    "variant_reset = variant.reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# Bayesian Ridge\n",
    "# -------------------------\n",
    "class BayesianRidgeImputer:\n",
    "    def __init__(self):\n",
    "        self.model = BayesianRidge()\n",
    "        self.categorical_indices = []  # To store indices of categorical variables\n",
    "        self.continuous_indices = []   # To store indices of continuous variables\n",
    "\n",
    "    def _identify_variable_types(self, X):\n",
    "        \"\"\"Identify categorical and continuous variables based on the data.\"\"\"\n",
    "        for i in range(X.shape[1]):\n",
    "            if np.all(np.isnan(X[:, i]) | (X[:, i] == np.floor(X[:, i]))):\n",
    "                self.categorical_indices.append(i)\n",
    "            else:\n",
    "                self.continuous_indices.append(i)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        mask = np.isnan(X)  # Mask for missing values\n",
    "        X_filled = X.copy()\n",
    "        self._identify_variable_types(X)\n",
    "\n",
    "        for i in range(X.shape[1]):\n",
    "            if mask[:, i].any():\n",
    "                # Median init\n",
    "                median_imputer = SimpleImputer(strategy='median')\n",
    "                X_filled[:, i] = median_imputer.fit_transform(X[:, i].reshape(-1, 1)).ravel()\n",
    "\n",
    "                temp_X = X_filled.copy()\n",
    "                temp_X[:, [j for j in range(X.shape[1]) if j != i]] = SimpleImputer(strategy='median').fit_transform(\n",
    "                    temp_X[:, [j for j in range(X.shape[1]) if j != i]]\n",
    "                )\n",
    "\n",
    "                not_missing_idx = ~mask[:, i]\n",
    "                missing_idx = mask[:, i]\n",
    "\n",
    "                if not_missing_idx.sum() > 0:\n",
    "                    self.model.fit(temp_X[not_missing_idx][:, [j for j in range(X.shape[1]) if j != i]], \n",
    "                                   X_filled[not_missing_idx, i])\n",
    "\n",
    "                    predicted_values = self.model.predict(temp_X[missing_idx][:, [j for j in range(X.shape[1]) if j != i]])\n",
    "\n",
    "                    if i in self.categorical_indices:\n",
    "                        X_filled[missing_idx, i] = np.round(predicted_values)\n",
    "                    else:\n",
    "                        X_filled[missing_idx, i] = np.maximum(0, predicted_values)\n",
    "\n",
    "        return X_filled\n",
    "\n",
    "# -------------------------\n",
    "# Complete Case Analysis\n",
    "# -------------------------\n",
    "mask_complete = ~np.isnan(features).any(axis=1)\n",
    "features_cca = features[mask_complete]\n",
    "variant_cca = variant_reset.loc[mask_complete].reset_index(drop=True)\n",
    "\n",
    "data_cca_full = pd.concat([variant_cca, pd.DataFrame(features_cca, columns=x_train.columns[1:-3]).reset_index(drop=True)], axis=1)\n",
    "data_cca_full.to_csv('train_data_CCA.csv', index=False)\n",
    "print(\"Complete Case Analysis\")\n",
    "\n",
    "# -------------------------\n",
    "# Multiple Imputation\n",
    "# -------------------------\n",
    "mi_imputer = IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=0)\n",
    "features_mi = mi_imputer.fit_transform(features)\n",
    "data_mi = pd.DataFrame(features_mi, columns=x_train.columns[1:-3])\n",
    "data_mi_full = pd.concat([variant_reset, data_mi.reset_index(drop=True)], axis=1)\n",
    "data_mi_full.to_csv('train_data_MI.csv', index=False)\n",
    "print(\"Multiple Imputation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
